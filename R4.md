## Log of Round 4 of #100DaysOfMLCode - Sushrut Tendulkar


### Day 91: May 5, 2020. Tuesday

**Today's Progress**: 

Built a complete RNN which will perform forward propagation.

<br> [Tutorial]() <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/d4a99d056834c0cba457d51d2d83917468194afd)


### Day 90: May 4, 2020. Monday

**Today's Progress**: 

Built a single cell of RNN using Numpy


<br> [Tutorial]() <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/b071a6f7c7cda6197c1d0eaa5772fee9bc7a5cd8)


### Day 89: May 2, 2020. Saturday

**Today's Progress**: 

Started watching tutorial on RNN by Andrej Karpathy


<br> [Tutorial](https://www.youtube.com/watch?v=yCC09vCHzF8) <br>

**Thoughts:** 

**Link to work:** [Click]()


### Day 88: May 1, 2020. Friday

**Today's Progress**: 

Continued learning through Sequence Models course on Coursera


<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click]()


### Day 87: April 30, 2020. Thursday

**Today's Progress**: 

Going through "Deep Learning" course on Coursera

What I learn't today?
1. Back propagation
2. Different types of RNN
3. Drawbacks of RNN
4. Vanishing Gradients
5. Gated Recurrent Unit

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click]()


### Day 86: April 29, 2020. Wednesday

**Today's Progress**: 

Decided to go through some of the classes again, from "Deep Learning" course. 

What I learn't today?
1. Where sequence models are useful
2. An example of sequence models
3. What is Recurrent Neural Network
4. What is forward propagation 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click]()


### Day 85: April 28, 2020. Tuesday

**Today's Progress**: 

1. Re-ran the whole models with 5lakh reviews and created LDA models for topic detection. Topics seem to be closely associated with content of each review. Need to go-through more reviews.
2. Trained model to predict score of reviews based on topic. Performance of models increased as follows,

Name -> Earlier -> Latest
----
LR   -> 79.8% ->  85.4%
----
SGD  -> 75.5%  -> 85.2%
-----
SVM Huber -> 54.6% -> 55.5%
-----------


<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/8c6a351cd7757aaacae42ff1ad2e0447052a2126)


### Day 84: April 27, 2020. Monday

**Today's Progress**: 

1. Re-ran the whole models with slightly higher dataset. 
2. Selected, all negative reviews and tried to identify topics associated with it using LDA model. Model was able to output correct topics for some of the negative reviews. For ex, this review - "10pm on a super bowl Sunday and they're already closed?? Weak, no wonder the hard Rock is dying off..." -  is under a specific `topic`, which talks about "always", "closed","average" etc. 
3. Next step is to predict rating for each reviews using these newly learnt topics, as features

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/545644e7f4468f497a86490afdb222208fd23269)


### Day 83: April 26, 2020. Sunday

**Today's Progress**: 

1. Worked on Data preprocessing again. Instead of selecting just reviews, I chose other features availabel in it like - date, business_id, ratings. Combined this with `Business` file
2. Using LDA, created 20 topics out of the reviews
3. Mapped each review with distibution of frequencies. (This is what I wanted to do in the beginning). Each review is not associated strongly with one topic. One of the reasons could be the less training data.
4. Using each of these topics' distribution, trained Logotsic Regression Model & SGD to predict the rating of each review. For LR f1 score is 79.8% and for SGD f1 score is 75.5%. SVM Huber got f1 score of 54.6%. NExt step is rerun the models using larger dataset

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/89b5aa3bb024ce78da2a210f2281af63711a0218)


### Day 82: April 25, 2020. Saturday

**Today's Progress**: 

Researched about different approcahes to solve Yelp dataset. Looks like Regression, Kmeans & LSTM are some of the models/techniques which work better on text data. 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click]()



### Day 81: April 24, 2020. Friday

**Today's Progress**: 

Spent time researching on sentiment analysis of text. The main objective of this project is to find the topic/context of each reviews so that it will be easy to find why certain negative reviews are negative. This can actually help the restaurant owners to improve the ratings. 
Also, finding sentiment polarity of reviews is easier because users would rate each review from 1-5, which itself can be used as sentiment score. 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click]()



### Day 80: April 23, 2020. Thursday

**Today's Progress**: 

Spent time working contextual word vectors. 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/5161ed95ca38505638d816613b58600969574ef0)


### Day 79: April 22, 2020. Wednesday

**Today's Progress**: 

Spent time working on understanding the output of the model.  Model performed well in identifying funny/unfunny reviews but not very accurate. Visualized the output using `bokeh`. 
Started working on contextual word vectors but couldn't load libraries properly. Need to try again. 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/34bb77fb6013443c6028cb7bae69dbf6fcb7f3ae)

### Day 78: April 21, 2020. Tuesday

**Today's Progress**: 
Created a spacy model to categorize text. This model would identify if the review is funny or unfunny. 

<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/3f3bf3037a002b9b9390d2a4894fa0e07651e1e4)


### Day 77: April 20, 2020. Monday

**Today's Progress**: 
1. Tried to play around with word wectors
2. using t-SNE reduced word vectors of 100 dimensions into two dimensional vectors
3. Visualized words using `bokeh`. 

<br> [Tutorial] <br>

**Thoughts:** It is interesting to note that all related words are closer in the 2-D graph

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/9c34695d00192567e8bde22396ebf76916a9be83)


### Day 76: April 19, 2020. Sunday

**Today's Progress**: 
1. I tried to process data again. It took few hours to preprocess 4 Lakh reviews (400,000) but model was able to create a valid topics using LDA. Some of the topics are Alcohol, Pizza, Japanese, Chinese Italian etc. 
2. Visulaized topics using `pyLDAvis`
3. Created 100 dimensional vectors for each of the words using `gensim`'s word2vec.  
4. Tried to find similar words for each word. 
<br>Ex: get_related_terms("dal"). Ans Masala, Korma, daal, curry, tikka_masala, paneer, sambar, chiken_tikka_masala
<br>Ex 2: get_related_terms('pasta'). Ans spaghetti, penne, lasagna, gnocchi, linguine, fettuccine, carbonara, pomodoro         , pastas, tortellini, fettuccini     
4. Played with word vectors using simple maths. 
<br>Ex : Lunch + Night - Day = ? (Ans: Dinner) . 


<br> [Tutorial] <br>

**Thoughts:** Feelig good after creating word vector and testing it's uses.

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/25c8c2411d6376ffbcd85fe5f2236af0c4242d43)



### Day 75: April 18, 2020. Saturday

**Today's Progress**: 
1. Worked on Phrase Modelling using gensim package. Model was able to group bigrams and trigrams based on proability of usage.
2. Worked on Topic Modelling using LDA. Created Bag of Words and created 50 topics from the reviews using `LdaMulticore` class. Because the dataset of reviews was trimmed to 1 Lakh reviews, each of the topics were not clear. Need to re-run the code with atleast 25 - 30 Lakh reviews ( 2.5 to 3 Million). Most probably I'll run it on Google Collab. 


<br> [Tutorial] <br>

**Thoughts:** File has 50 Lakhs (5 million) reviews and a simple preprocessing for cleaning the dataset itself would take 13Hrs on my Laptop. I had to reduce the number of reviews to 1 Lakh (100,000) for practice purpose. In the second iteration, I would want to try this on one of the cloud platforms. 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/86fca709eac035e99234aa7e16e6627b46deff43)


### Day 74: April 17, 2020. Friday

**Today's Progress**: 
1. Parsed a sample review using `spacy` library
2. Performed text normalization -  Lemmatization, Part of Speech etc
3. Using `displacy` rendered the text

<br> [Tutorial] <br>

**Thoughts:** Spacy threw error while loading the file. Fixed using [this](https://github.com/explosion/spaCy/issues/4577) link

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/0df39468e3abc0ada3fc9b94adb55c296b6b9ade)

### Day 73: April 16, 2020. Thursday

**Today's Progress**: 
1. Read the dataset into jupyter. 
2. Selected only the Restaurants and stored their ids
3. Extracted all reviews for restaurants and stored in separate file.
4. Read few sample reviews
<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/f453362c773beae659d58da09b70349a36af5cad)

### Day 72: April 15, 2020. Wednesday

**Today's Progress**: Took a break of 3 months as I had to work on another project. For next 30 days, I'll be working on a NLP project. Downloaded Yelp data set and read few reviews from it. I also read through a tutorial on Yelp data set analysis. 

[Tutorial - ](https://www.youtube.com/watch?v=6zm9NC9uRkk) <br>

**Thoughts:** Feeling good to be back on track for 100days of coding challenge

**Link to work:** [Click]()
