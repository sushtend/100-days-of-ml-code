## Log of Round 4 of #100DaysOfMLCode - Sushrut Tendulkar


### Day 77: April 20, 2020. Monday

**Today's Progress**: 
1. Tried to play around with word wectors
2. using t-SNE reduced word vectors of 100 dimensions into two dimensional vectors
3. Visualized words using `bokeh`. 

<br> [Tutorial] <br>

**Thoughts:** It is interesting to note that all related words are closer in the 2-D graph

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/9c34695d00192567e8bde22396ebf76916a9be83)


### Day 76: April 19, 2020. Sunday

**Today's Progress**: 
1. I tried to process data again. It took few hours to preprocess 4 Lakh reviews (400,000) but model was able to create a valid topics using LDA. Some of the topics are Alcohol, Pizza, Japanese, Chinese Italian etc. 
2. Visulaized topics using `pyLDAvis`
3. Created 100 dimensional vectors for each of the words using `gensim`'s word2vec.  
4. Tried to find similar words for each word. 
<br>Ex: get_related_terms("dal"). Ans Masala, Korma, daal, curry, tikka_masala, paneer, sambar, chiken_tikka_masala
<br>Ex 2: get_related_terms('pasta'). Ans spaghetti, penne, lasagna, gnocchi, linguine, fettuccine, carbonara, pomodoro         , pastas, tortellini, fettuccini     
4. Played with word vectors using simple maths. 
<br>Ex : Lunch + Night - Day = ? (Ans: Dinner) . 


<br> [Tutorial] <br>

**Thoughts:** Feelig good after creating word vector and testing it's uses.

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/25c8c2411d6376ffbcd85fe5f2236af0c4242d43)



### Day 75: April 18, 2020. Saturday

**Today's Progress**: 
1. Worked on Phrase Modelling using gensim package. Model was able to group bigrams and trigrams based on proability of usage.
2. Worked on Topic Modelling using LDA. Created Bag of Words and created 50 topics from the reviews using `LdaMulticore` class. Because the dataset of reviews was trimmed to 1 Lakh reviews, each of the topics were not clear. Need to re-run the code with atleast 25 - 30 Lakh reviews ( 2.5 to 3 Million). Most probably I'll run it on Google Collab. 


<br> [Tutorial] <br>

**Thoughts:** File has 50 Lakhs (5 million) reviews and a simple preprocessing for cleaning the dataset itself would take 13Hrs on my Laptop. I had to reduce the number of reviews to 1 Lakh (100,000) for practice purpose. In the second iteration, I would want to try this on one of the cloud platforms. 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/86fca709eac035e99234aa7e16e6627b46deff43)


### Day 74: April 17, 2020. Friday

**Today's Progress**: 
1. Parsed a sample review using `spacy` library
2. Performed text normalization -  Lemmatization, Part of Speech etc
3. Using `displacy` rendered the text

<br> [Tutorial] <br>

**Thoughts:** Spacy threw error while loading the file. Fixed using [this](https://github.com/explosion/spaCy/issues/4577) link

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/0df39468e3abc0ada3fc9b94adb55c296b6b9ade)

### Day 73: April 16, 2020. Thursday

**Today's Progress**: 
1. Read the dataset into jupyter. 
2. Selected only the Restaurants and stored their ids
3. Extracted all reviews for restaurants and stored in separate file.
4. Read few sample reviews
<br> [Tutorial] <br>

**Thoughts:** 

**Link to work:** [Click](https://github.com/sushtend/100-days-of-ml-code/commit/f453362c773beae659d58da09b70349a36af5cad)

### Day 72: April 15, 2020. Wednesday

**Today's Progress**: Took a break of 3 months as I had to work on another project. For next 30 days, I'll be working on a NLP project. Downloaded Yelp data set and read few reviews from it. I also read through a tutorial on Yelp data set analysis. 

[Tutorial - ](https://www.youtube.com/watch?v=6zm9NC9uRkk) <br>

**Thoughts:** Feeling good to be back on track for 100days of coding challenge

**Link to work:** [Click]()
