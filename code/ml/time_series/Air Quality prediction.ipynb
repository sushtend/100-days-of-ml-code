{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRC\n",
    "1. https://machinelearningmastery.com/how-to-develop-machine-learning-models-for-multivariate-multi-step-air-pollution-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import nan\n",
    "from numpy import array\n",
    "from numpy import savetxt\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('AirQualityPrediction/TrainingData.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>chunkID</th>\n",
       "      <th>position_within_chunk</th>\n",
       "      <th>month_most_common</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>Solar.radiation_64</th>\n",
       "      <th>WindDirection..Resultant_1</th>\n",
       "      <th>WindDirection..Resultant_1018</th>\n",
       "      <th>WindSpeed..Resultant_1</th>\n",
       "      <th>...</th>\n",
       "      <th>target_4_6006</th>\n",
       "      <th>target_4_8003</th>\n",
       "      <th>target_5_6006</th>\n",
       "      <th>target_7_57</th>\n",
       "      <th>target_8_57</th>\n",
       "      <th>target_8_4002</th>\n",
       "      <th>target_8_6004</th>\n",
       "      <th>target_8_8003</th>\n",
       "      <th>target_9_4002</th>\n",
       "      <th>target_9_8003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>117.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.748424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.341606</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.013752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.679280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>231.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.144120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.130631</td>\n",
       "      <td>1.195779</td>\n",
       "      <td>2.722099</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.426751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>247.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.932469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.136395</td>\n",
       "      <td>1.409658</td>\n",
       "      <td>3.110970</td>\n",
       "      <td>3.888712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.683732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>219.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.477711</td>\n",
       "      <td>2.041574</td>\n",
       "      <td>3.208188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.831243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.217102</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>2.138792</td>\n",
       "      <td>3.499841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.625658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.687052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.170984</td>\n",
       "      <td>1.604094</td>\n",
       "      <td>2.236010</td>\n",
       "      <td>3.305406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.833469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>330.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.677850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951554</td>\n",
       "      <td>1.555485</td>\n",
       "      <td>1.652703</td>\n",
       "      <td>2.430445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.854715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>316.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.549019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951554</td>\n",
       "      <td>1.711033</td>\n",
       "      <td>1.458267</td>\n",
       "      <td>1.361049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.595508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>285.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.928495</td>\n",
       "      <td>1.623537</td>\n",
       "      <td>1.361049</td>\n",
       "      <td>1.263832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.621206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>337.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.815897</td>\n",
       "      <td>1.380493</td>\n",
       "      <td>1.263832</td>\n",
       "      <td>1.166614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.004452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowID  chunkID  position_within_chunk  month_most_common   weekday  hour  \\\n",
       "0      1        1                      1                 10  Saturday    21   \n",
       "1      2        1                      2                 10  Saturday    22   \n",
       "2      3        1                      3                 10  Saturday    23   \n",
       "3      4        1                      4                 10    Sunday     0   \n",
       "4      5        1                      5                 10    Sunday     1   \n",
       "5      6        1                      6                 10    Sunday     2   \n",
       "6      7        1                      7                 10    Sunday     3   \n",
       "7      8        1                      8                 10    Sunday     4   \n",
       "8      9        1                      9                 10    Sunday     5   \n",
       "9     10        1                     10                 10    Sunday     6   \n",
       "\n",
       "   Solar.radiation_64  WindDirection..Resultant_1  \\\n",
       "0                0.01                       117.0   \n",
       "1                0.01                       231.0   \n",
       "2                0.01                       247.0   \n",
       "3                0.01                       219.0   \n",
       "4                0.01                         2.0   \n",
       "5                0.01                       288.0   \n",
       "6                0.01                       330.0   \n",
       "7                0.01                       316.0   \n",
       "8                0.01                       285.0   \n",
       "9                0.05                       337.0   \n",
       "\n",
       "   WindDirection..Resultant_1018  WindSpeed..Resultant_1  ...  target_4_6006  \\\n",
       "0                          187.0                     0.3  ...       1.748424   \n",
       "1                          202.0                     0.5  ...       2.144120   \n",
       "2                          227.0                     0.5  ...       1.932469   \n",
       "3                          218.0                     0.2  ...       2.088907   \n",
       "4                          216.0                     0.2  ...       2.604232   \n",
       "5                            2.0                     0.3  ...       2.687052   \n",
       "6                            8.0                     0.3  ...       2.677850   \n",
       "7                            4.0                     0.8  ...       2.549019   \n",
       "8                          342.0                     0.7  ...       2.226941   \n",
       "9                          352.0                     1.3  ...       1.996885   \n",
       "\n",
       "   target_4_8003  target_5_6006  target_7_57  target_8_57  target_8_4002  \\\n",
       "0            NaN            NaN     5.130631     1.341606       2.138792   \n",
       "1            NaN            NaN     5.130631     1.195779       2.722099   \n",
       "2            NaN            NaN     5.136395     1.409658       3.110970   \n",
       "3            NaN            NaN     5.217102     1.477711       2.041574   \n",
       "4            NaN            NaN     5.217102     1.458267       2.138792   \n",
       "5            NaN            NaN     5.170984     1.604094       2.236010   \n",
       "6            NaN            NaN     2.951554     1.555485       1.652703   \n",
       "7            NaN            NaN     2.951554     1.711033       1.458267   \n",
       "8            NaN            NaN     2.928495     1.623537       1.361049   \n",
       "9            NaN            NaN     1.815897     1.380493       1.263832   \n",
       "\n",
       "   target_8_6004  target_8_8003  target_9_4002  target_9_8003  \n",
       "0       3.013752            NaN       5.679280            NaN  \n",
       "1       3.888712            NaN       7.426751            NaN  \n",
       "2       3.888712            NaN       7.683732            NaN  \n",
       "3       3.208188            NaN       4.831243            NaN  \n",
       "4       3.499841            NaN       4.625658            NaN  \n",
       "5       3.305406            NaN       5.833469            NaN  \n",
       "6       2.430445            NaN       3.854715            NaN  \n",
       "7       1.361049            NaN       2.595508            NaN  \n",
       "8       1.263832            NaN       2.621206            NaN  \n",
       "9       1.166614            NaN       2.004452            NaN  \n",
       "\n",
       "[10 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_ids = list(set(dataset.values[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then collect all rows for each chunk identifier and store them in a dictionary for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(values, chunk_ix=1):\n",
    "\tchunks = dict()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values.iloc[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values.iloc[:, chunk_ix] == chunk_id\n",
    "\t\tchunks[chunk_id] = values.loc[selection, :]\n",
    "\treturn chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Each chunk covers an interval of eight days of hourly observations, although the number of actual observations within each chunk may vary widely.\n",
    "\n",
    "<br>We can split each chunk into the first five days of observations for training and the last three for test.\n",
    "\n",
    "<br>Each observation has a row called ‘position_within_chunk‘ that varies from 1 to 192 (8 days * 24 hours). We can therefore take all rows with a value in this column that is less than or equal to 120 (5 * 24) as training data and any values more than 120 as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each chunk into train/test sets\n",
    "def split_train_test(chunks, row_in_chunk_ix=2):\n",
    "\ttrain, test = list(), list()\n",
    "\t# first 5 days of hourly observations for train\n",
    "\tcut_point = 5 * 24\n",
    "\t# enumerate chunks\n",
    "\tfor k,rows in chunks.items():\n",
    "\t\t# split chunk rows by 'position_within_chunk'\n",
    "\t\ttrain_rows = rows[rows[:,row_in_chunk_ix] <= cut_point, :]\n",
    "\t\ttest_rows = rows[rows[:,row_in_chunk_ix] > cut_point, :]\n",
    "\t\tif len(train_rows) == 0 or len(test_rows) == 0:\n",
    "\t\t\tprint('>dropping chunk=%d: train=%s, test=%s' % (k, train_rows.shape, test_rows.shape))\n",
    "\t\t\tcontinue\n",
    "\t\t# store with chunk id, position in chunk, hour and all targets\n",
    "\t\tindices = [1,2,5] + [x for x in range(56,train_rows.shape[1])]\n",
    "\t\ttrain.append(train_rows[:, indices])\n",
    "\t\ttest.append(test_rows[:, indices])\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2 ,3, 4, 5, 10, 17, 24, 48, 72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the rows in a test chunk to forecasts\n",
    "def to_forecasts(test_chunks, row_in_chunk_ix=1):\n",
    "\t# get lead times\n",
    "\tlead_times = get_lead_times()\n",
    "\t# first 5 days of hourly observations for train\n",
    "\tcut_point = 5 * 24\n",
    "\tforecasts = list()\n",
    "\t# enumerate each chunk\n",
    "\tfor rows in test_chunks:\n",
    "\t\tchunk_id = rows[0, 0]\n",
    "\t\t# enumerate each lead time\n",
    "\t\tfor tau in lead_times:\n",
    "\t\t\t# determine the row in chunk we want for the lead time\n",
    "\t\t\toffset = cut_point + tau\n",
    "\t\t\t# retrieve data for the lead time using row number in chunk\n",
    "\t\t\trow_for_tau = rows[rows[:,row_in_chunk_ix]==offset, :]\n",
    "\t\t\t# check if we have data\n",
    "\t\t\tif len(row_for_tau) == 0:\n",
    "\t\t\t\t# create a mock row [chunk, position, hour] + [nan...]\n",
    "\t\t\t\trow = [chunk_id, offset, nan] + [nan for _ in range(39)]\n",
    "\t\t\t\tforecasts.append(row)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# store the forecast row\n",
    "\t\t\t\tforecasts.append(row_for_tau[0])\n",
    "\treturn array(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">dropping chunk=69: train=(0, 95), test=(28, 95)\n",
      "Train Rows: (23514, 42)\n",
      "Test Rows: (2070, 42)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('AirQualityPrediction/TrainingData.csv', header=0)\n",
    "# group data by chunks\n",
    "values = dataset.values\n",
    "chunks = to_chunks(values)\n",
    "# split into train/test\n",
    "train, test = split_train_test(chunks)\n",
    "# flatten training chunks to rows\n",
    "train_rows = array([row for rows in train for row in rows])\n",
    "# print(train_rows.shape)\n",
    "print('Train Rows: %s' % str(train_rows.shape))\n",
    "# reduce train to forecast lead times only\n",
    "test_rows = to_forecasts(test)\n",
    "print('Test Rows: %s' % str(test_rows.shape))\n",
    "# save datasets\n",
    "savetxt('AirQualityPrediction/naive_train.csv', train_rows, delimiter=',')\n",
    "savetxt('AirQualityPrediction/naive_test.csv', test_rows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_forecasts(test_chunks):\n",
    "\tpredictions = list()\n",
    "\t# enumerate chunks to forecast\n",
    "\tfor rows in test_chunks:\n",
    "\t\t# enumerate targets for chunk\n",
    "\t\tchunk_predictions = list()\n",
    "\t\tfor j in range(3, rows.shape[1]):\n",
    "\t\t\tyhat = rows[:, j]\n",
    "\t\t\tchunk_predictions.append(yhat)\n",
    "\t\tchunk_predictions = array(chunk_predictions)\n",
    "\t\tpredictions.append(chunk_predictions)\n",
    "\treturn array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the error between an actual and predicted value\n",
    "def calculate_error(actual, predicted):\n",
    "\t# give the full actual value if predicted is nan\n",
    "\tif isnan(predicted):\n",
    "\t\treturn abs(actual)\n",
    "\t# calculate abs difference\n",
    "\treturn abs(actual - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a forecast in the format [chunk][variable][time]\n",
    "def evaluate_forecasts(predictions, testset):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttotal_mae, times_mae = 0.0, [0.0 for _ in range(len(lead_times))]\n",
    "\ttotal_c, times_c = 0, [0 for _ in range(len(lead_times))]\n",
    "\t# enumerate test chunks\n",
    "\tfor i in range(len(test_chunks)):\n",
    "\t\t# convert to forecasts\n",
    "\t\tactual = testset[i]\n",
    "\t\tpredicted = predictions[i]\n",
    "\t\t# enumerate target variables\n",
    "\t\tfor j in range(predicted.shape[0]):\n",
    "\t\t\t# enumerate lead times\n",
    "\t\t\tfor k in range(len(lead_times)):\n",
    "\t\t\t\t# skip if actual in nan\n",
    "\t\t\t\tif isnan(actual[j, k]):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# calculate error\n",
    "\t\t\t\terror = calculate_error(actual[j, k], predicted[j, k])\n",
    "\t\t\t\t# update statistics\n",
    "\t\t\t\ttotal_mae += error\n",
    "\t\t\t\ttimes_mae[k] += error\n",
    "\t\t\t\ttotal_c += 1\n",
    "\t\t\t\ttimes_c[k] += 1\n",
    "\t# normalize summed absolute errors\n",
    "\ttotal_mae /= total_c\n",
    "\ttimes_mae = [times_mae[i]/times_c[i] for i in range(len(times_mae))]\n",
    "\treturn total_mae, times_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_error(name, total_mae, times_mae):\n",
    "\t# print summary\n",
    "\tlead_times = get_lead_times()\n",
    "\tformatted = ['+%d %.3f' % (lead_times[i], times_mae[i]) for i in range(len(lead_times))]\n",
    "\ts_scores = ', '.join(formatted)\n",
    "\tprint('%s: [%.3f MAE] %s' % (name, total_mae, s_scores))\n",
    "\t# plot summary\n",
    "\tpyplot.plot([str(x) for x in lead_times], times_mae, marker='.')\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_to_series(chunk_train, col_ix, n_steps=5*24):\n",
    "\t# lay out whole series\n",
    "\tdata = [nan for _ in range(n_steps)]\n",
    "\t# mark all available data\n",
    "\tfor i in range(len(chunk_train)):\n",
    "\t\t# get position in chunk\n",
    "\t\tposition = int(chunk_train[i, 1] - 1)\n",
    "\t\t# store data\n",
    "\t\tdata[position] = chunk_train[i, col_ix]\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate series of hours (in place) in 24 hour time\n",
    "def interpolate_hours(hours):\n",
    "\t# find the first hour\n",
    "\tix = -1\n",
    "\tfor i in range(len(hours)):\n",
    "\t\tif not isnan(hours[i]):\n",
    "\t\t\tix = i\n",
    "\t\t\tbreak\n",
    "\t# fill-forward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix+1, len(hours)):\n",
    "\t\t# increment hour\n",
    "\t\thour += 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24\n",
    "\t# fill-backward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix-1, -1, -1):\n",
    "\t\t# decrement hour\n",
    "\t\thour -= 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f8b9cfab6827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prepare sequence of hours for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# interpolate hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterpolate_hours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare sequence of hours for the chunk\n",
    "hours = variable_to_series(rows, 2)\n",
    "# interpolate hours\n",
    "interpolate_hours(hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data\n",
    "def impute_missing(train_chunks, rows, hours, series, col_ix):\n",
    "\t# impute missing using the median value for hour in all series\n",
    "\timputed = list()\n",
    "\tfor i in range(len(series)):\n",
    "\t\tif isnan(series[i]):\n",
    "\t\t\t# collect all rows across all chunks for the hour\n",
    "\t\t\tall_rows = list()\n",
    "\t\t\tfor rows in train_chunks:\n",
    "\t\t\t\t[all_rows.append(row) for row in rows[rows[:,2]==hours[i]]]\n",
    "\t\t\t# calculate the central tendency for target\n",
    "\t\t\tall_rows = array(all_rows)\n",
    "\t\t\t# fill with median value\n",
    "\t\t\tvalue = nanmedian(all_rows[:, col_ix])\n",
    "\t\t\tif isnan(value):\n",
    "\t\t\t\tvalue = 0.0\n",
    "\t\t\timputed.append(value)\n",
    "\t\telse:\n",
    "\t\t\timputed.append(series[i])\n",
    "\treturn imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_for_lead_time(series, n_lag, lead_time):\n",
    "\tsamples = list()\n",
    "\t# enumerate observations and create input/output patterns\n",
    "\tfor i in range(n_lag, len(series)):\n",
    "\t\tend_ix = i + (lead_time - 1)\n",
    "\t\t# check if can create a pattern\n",
    "\t\tif end_ix >= len(series):\n",
    "\t\t\tbreak\n",
    "\t\t# retrieve input and output\n",
    "\t\tstart_ix = i - n_lag\n",
    "\t\trow = series[start_ix:i] + [series[end_ix]]\n",
    "\t\tsamples.append(row)\n",
    "\treturn samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  8]\n",
      " [ 1  2  3  9]\n",
      " [ 2  3  4 10]\n",
      " [ 3  4  5 11]\n",
      " [ 4  5  6 12]\n",
      " [ 5  6  7 13]\n",
      " [ 6  7  8 14]\n",
      " [ 7  8  9 15]\n",
      " [ 8  9 10 16]\n",
      " [ 9 10 11 17]\n",
      " [10 11 12 18]\n",
      " [11 12 13 19]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    " \n",
    "# created input/output patterns from a sequence\n",
    "def supervised_for_lead_time(series, n_lag, lead_time):\n",
    "\tdata = list()\n",
    "\t# enumerate observations and create input/output patterns\n",
    "\tfor i in range(n_lag, len(series)):\n",
    "\t\tend_ix = i + (lead_time - 1)\n",
    "\t\t# check if can create a pattern\n",
    "\t\tif end_ix >= len(series):\n",
    "\t\t\tbreak\n",
    "\t\t# retrieve input and output\n",
    "\t\tstart_ix = i - n_lag\n",
    "\t\trow = series[start_ix:i] + [series[end_ix]]\n",
    "\t\tdata.append(row)\n",
    "\treturn array(data)\n",
    " \n",
    "# define test dataset\n",
    "data = [x for x in range(20)]\n",
    "# convert to supervised format\n",
    "result = supervised_for_lead_time(data, 3, 6)\n",
    "# display result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervised learning data for each lead time for this target\n",
    "def target_to_supervised(chunks, rows, hours, col_ix, n_lag):\n",
    "\ttrain_lead_times = list()\n",
    "\t# get series\n",
    "\tseries = variable_to_series(rows, col_ix)\n",
    "\tif not has_data(series):\n",
    "\t\treturn None, [nan for _ in range(n_lag)]\n",
    "\t# impute\n",
    "\timputed = impute_missing(chunks, rows, hours, series, col_ix)\n",
    "\t# prepare test sample for chunk-variable\n",
    "\ttest_sample = array(imputed[-n_lag:])\n",
    "\t# enumerate lead times\n",
    "\tlead_times = get_lead_times()\n",
    "\tfor lead_time in lead_times:\n",
    "\t\t# make input/output data from series\n",
    "\t\ttrain_samples = supervised_for_lead_time(imputed, n_lag, lead_time)\n",
    "\t\ttrain_lead_times.append(train_samples)\n",
    "\treturn train_lead_times, test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training [var][lead time][sample] and test [chunk][var][sample]\n",
    "def data_prep(chunks, n_lag, n_vars=39):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttrain_data = [[list() for _ in range(len(lead_times))] for _ in range(n_vars)]\n",
    "\ttest_data = [[list() for _ in range(n_vars)] for _ in range(len(chunks))]\n",
    "\t# enumerate targets for chunk\n",
    "\tfor var in range(n_vars):\n",
    "\t\t# convert target number into column number\n",
    "\t\tcol_ix = 3 + var\n",
    "\t\t# enumerate chunks to forecast\n",
    "\t\tfor c_id in range(1,len(chunks)):\n",
    "\t\t\trows = chunks[c_id]\n",
    "\t\t\t# prepare sequence of hours for the chunk\n",
    "\t\t\thours = variable_to_series(rows, 2)\n",
    "\t\t\t# interpolate hours\n",
    "\t\t\tinterpolate_hours(hours)\n",
    "\t\t\t# check for no data\n",
    "\t\t\tif not has_data(rows[:, col_ix]):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# convert series into training data for each lead time\n",
    "\t\t\ttrain, test_sample = target_to_supervised(chunks, rows, hours, col_ix, n_lag)\n",
    "\t\t\t# store test sample for this var-chunk\n",
    "\t\t\ttest_data[c_id][var] = test_sample\n",
    "\t\t\tif train is not None:\n",
    "\t\t\t\t# store samples per lead time\n",
    "\t\t\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\t\t\t# add all rows to the existing list of rows\n",
    "\t\t\t\t\ttrain_data[var][lead_time].extend(train[lead_time])\n",
    "\t\t# convert all rows for each var-lead time to a numpy array\n",
    "\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\ttrain_data[var][lead_time] = array(train_data[var][lead_time])\n",
    "\treturn array(train_data), array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-69e681349e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# convert training data into supervised learning data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_lag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# save train and test sets to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-996864ce3492>\u001b[0m in \u001b[0;36mdata_prep\u001b[0;34m(chunks, n_lag, n_vars)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0;31m# prepare sequence of hours for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                         \u001b[0;31m# interpolate hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0minterpolate_hours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-57e34ae98864>\u001b[0m in \u001b[0;36mvariable_to_series\u001b[0;34m(chunk_train, col_ix, n_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;31m# get position in chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;31m# store data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 1)"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train = read_csv('AirQualityPrediction/naive_train.csv', delimiter=',')\n",
    "test = read_csv('AirQualityPrediction/naive_test.csv', delimiter=',')\n",
    "# group data by chunks\n",
    "train_chunks = to_chunks(train)\n",
    "test_chunks = to_chunks(test)\n",
    "# convert training data into supervised learning data\n",
    "n_lag = 12\n",
    "train_data, test_data = data_prep(train_chunks, n_lag)\n",
    "print(train_data.shape, test_data.shape)\n",
    "# save train and test sets to file\n",
    "save('AirQualityPrediction/supervised_train.npy', train_data)\n",
    "save('AirQualityPrediction/supervised_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-8aa727ce2753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-57e34ae98864>\u001b[0m in \u001b[0;36mvariable_to_series\u001b[0;34m(chunk_train, col_ix, n_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;31m# get position in chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;31m# store data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 1)"
     ]
    }
   ],
   "source": [
    "c_id=1\n",
    "rows = train_chunks[c_id]\n",
    "hours = variable_to_series(rows, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from numpy import loadtxt\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from numpy import count_nonzero\n",
    "from numpy import unique\n",
    "from numpy import array\n",
    "from numpy import nanmedian\n",
    "from numpy import save\n",
    "\n",
    "# split the dataset by 'chunkID', return a list of chunks\n",
    "def to_chunks(values, chunk_ix=0):\n",
    "\tchunks = list()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values[:, chunk_ix] == chunk_id\n",
    "\t\tchunks.append(values[selection, :])\n",
    "\treturn chunks\n",
    "\n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2, 3, 4, 5, 10, 17, 24, 48, 72]\n",
    "\n",
    "# interpolate series of hours (in place) in 24 hour time\n",
    "def interpolate_hours(hours):\n",
    "\t# find the first hour\n",
    "\tix = -1\n",
    "\tfor i in range(len(hours)):\n",
    "\t\tif not isnan(hours[i]):\n",
    "\t\t\tix = i\n",
    "\t\t\tbreak\n",
    "\t# fill-forward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix+1, len(hours)):\n",
    "\t\t# increment hour\n",
    "\t\thour += 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24\n",
    "\t# fill-backward\n",
    "\thour = hours[ix]\n",
    "\tfor i in range(ix-1, -1, -1):\n",
    "\t\t# decrement hour\n",
    "\t\thour -= 1\n",
    "\t\t# check for a fill\n",
    "\t\tif isnan(hours[i]):\n",
    "\t\t\thours[i] = hour % 24\n",
    "\n",
    "# return true if the array has any non-nan values\n",
    "def has_data(data):\n",
    "\treturn count_nonzero(isnan(data)) < len(data)\n",
    "\n",
    "# impute missing data\n",
    "def impute_missing(train_chunks, rows, hours, series, col_ix):\n",
    "\t# impute missing using the median value for hour in all series\n",
    "\timputed = list()\n",
    "\tfor i in range(len(series)):\n",
    "\t\tif isnan(series[i]):\n",
    "\t\t\t# collect all rows across all chunks for the hour\n",
    "\t\t\tall_rows = list()\n",
    "\t\t\tfor rows in train_chunks:\n",
    "\t\t\t\t[all_rows.append(row) for row in rows[rows[:,2]==hours[i]]]\n",
    "\t\t\t# calculate the central tendency for target\n",
    "\t\t\tall_rows = array(all_rows)\n",
    "\t\t\t# fill with median value\n",
    "\t\t\tvalue = nanmedian(all_rows[:, col_ix])\n",
    "\t\t\tif isnan(value):\n",
    "\t\t\t\tvalue = 0.0\n",
    "\t\t\timputed.append(value)\n",
    "\t\telse:\n",
    "\t\t\timputed.append(series[i])\n",
    "\treturn imputed\n",
    "\n",
    "# layout a variable with breaks in the data for missing positions\n",
    "def variable_to_series(chunk_train, col_ix, n_steps=5*24):\n",
    "\t# lay out whole series\n",
    "\tdata = [nan for _ in range(n_steps)]\n",
    "\t# mark all available data\n",
    "\tfor i in range(len(chunk_train)):\n",
    "\t\t# get position in chunk\n",
    "\t\tposition = int(chunk_train[i, 1] - 1)\n",
    "\t\t# store data\n",
    "\t\tdata[position] = chunk_train[i, col_ix]\n",
    "\treturn data\n",
    "\n",
    "# created input/output patterns from a sequence\n",
    "def supervised_for_lead_time(series, n_lag, lead_time):\n",
    "\tsamples = list()\n",
    "\t# enumerate observations and create input/output patterns\n",
    "\tfor i in range(n_lag, len(series)):\n",
    "\t\tend_ix = i + (lead_time - 1)\n",
    "\t\t# check if can create a pattern\n",
    "\t\tif end_ix >= len(series):\n",
    "\t\t\tbreak\n",
    "\t\t# retrieve input and output\n",
    "\t\tstart_ix = i - n_lag\n",
    "\t\trow = series[start_ix:i] + [series[end_ix]]\n",
    "\t\tsamples.append(row)\n",
    "\treturn samples\n",
    "\n",
    "# create supervised learning data for each lead time for this target\n",
    "def target_to_supervised(chunks, rows, hours, col_ix, n_lag):\n",
    "\ttrain_lead_times = list()\n",
    "\t# get series\n",
    "\tseries = variable_to_series(rows, col_ix)\n",
    "\tif not has_data(series):\n",
    "\t\treturn None, [nan for _ in range(n_lag)]\n",
    "\t# impute\n",
    "\timputed = impute_missing(chunks, rows, hours, series, col_ix)\n",
    "\t# prepare test sample for chunk-variable\n",
    "\ttest_sample = array(imputed[-n_lag:])\n",
    "\t# enumerate lead times\n",
    "\tlead_times = get_lead_times()\n",
    "\tfor lead_time in lead_times:\n",
    "\t\t# make input/output data from series\n",
    "\t\ttrain_samples = supervised_for_lead_time(imputed, n_lag, lead_time)\n",
    "\t\ttrain_lead_times.append(train_samples)\n",
    "\treturn train_lead_times, test_sample\n",
    "\n",
    "# prepare training [var][lead time][sample] and test [chunk][var][sample]\n",
    "def data_prep(chunks, n_lag, n_vars=39):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttrain_data = [[list() for _ in range(len(lead_times))] for _ in range(n_vars)]\n",
    "\ttest_data = [[list() for _ in range(n_vars)] for _ in range(len(chunks))]\n",
    "\t# enumerate targets for chunk\n",
    "\tfor var in range(n_vars):\n",
    "\t\t# convert target number into column number\n",
    "\t\tcol_ix = 3 + var\n",
    "\t\t# enumerate chunks to forecast\n",
    "\t\tfor c_id in range(len(chunks)):\n",
    "\t\t\trows = chunks[c_id]\n",
    "\t\t\t# prepare sequence of hours for the chunk\n",
    "\t\t\thours = variable_to_series(rows, 2)\n",
    "\t\t\t# interpolate hours\n",
    "\t\t\tinterpolate_hours(hours)\n",
    "\t\t\t# check for no data\n",
    "\t\t\tif not has_data(rows[:, col_ix]):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# convert series into training data for each lead time\n",
    "\t\t\ttrain, test_sample = target_to_supervised(chunks, rows, hours, col_ix, n_lag)\n",
    "\t\t\t# store test sample for this var-chunk\n",
    "\t\t\ttest_data[c_id][var] = test_sample\n",
    "\t\t\tif train is not None:\n",
    "\t\t\t\t# store samples per lead time\n",
    "\t\t\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\t\t\t# add all rows to the existing list of rows\n",
    "\t\t\t\t\ttrain_data[var][lead_time].extend(train[lead_time])\n",
    "\t\t# convert all rows for each var-lead time to a numpy array\n",
    "\t\tfor lead_time in range(len(lead_times)):\n",
    "\t\t\ttrain_data[var][lead_time] = array(train_data[var][lead_time])\n",
    "\treturn array(train_data), array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 10) (207, 39)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train = loadtxt('AirQualityPrediction/naive_train.csv', delimiter=',')\n",
    "test = loadtxt('AirQualityPrediction/naive_test.csv', delimiter=',')\n",
    "# group data by chunks\n",
    "train_chunks = to_chunks(train)\n",
    "test_chunks = to_chunks(test)\n",
    "# convert training data into supervised learning data\n",
    "n_lag = 12\n",
    "train_data, test_data = data_prep(train_chunks, n_lag)\n",
    "print(train_data.shape, test_data.shape)\n",
    "# save train and test sets to file\n",
    "save('AirQualityPrediction/supervised_train.npy', train_data)\n",
    "save('AirQualityPrediction/supervised_test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate linear algorithms\n",
    "from numpy import load\n",
    "from numpy import loadtxt\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from numpy import count_nonzero\n",
    "from numpy import unique\n",
    "from numpy import array\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# split the dataset by 'chunkID', return a list of chunks\n",
    "def to_chunks(values, chunk_ix=0):\n",
    "\tchunks = list()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values[:, chunk_ix] == chunk_id\n",
    "\t\tchunks.append(values[selection, :])\n",
    "\treturn chunks\n",
    "\n",
    "# return true if the array has any non-nan values\n",
    "def has_data(data):\n",
    "\treturn count_nonzero(isnan(data)) < len(data)\n",
    "\n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2, 3, 4, 5, 10, 17, 24, 48, 72]\n",
    "\n",
    "# fit a single model\n",
    "def fit_model(model, X, y):\n",
    "\t# clone the model configuration\n",
    "\tlocal_model = clone(model)\n",
    "\t# fit the model\n",
    "\tlocal_model.fit(X, y)\n",
    "\treturn local_model\n",
    "\n",
    "# fit one model for each variable and each forecast lead time [var][time][model]\n",
    "def fit_models(model, train):\n",
    "\t# prepare structure for saving models\n",
    "\tmodels = [[list() for _ in range(train.shape[1])] for _ in range(train.shape[0])]\n",
    "\t# enumerate vars\n",
    "\tfor i in range(train.shape[0]):\n",
    "\t\t# enumerate lead times\n",
    "\t\tfor j in range(train.shape[1]):\n",
    "\t\t\t# get data\n",
    "\t\t\tdata = train[i, j]\n",
    "\t\t\tX, y = data[:, :-1], data[:, -1]\n",
    "\t\t\t# fit model\n",
    "\t\t\tlocal_model = fit_model(model, X, y)\n",
    "\t\t\tmodels[i][j].append(local_model)\n",
    "\treturn models\n",
    "\n",
    "# return forecasts as [chunks][var][time]\n",
    "def make_predictions(models, test):\n",
    "\tlead_times = get_lead_times()\n",
    "\tpredictions = list()\n",
    "\t# enumerate chunks\n",
    "\tfor i in range(test.shape[0]):\n",
    "\t\t# enumerate variables\n",
    "\t\tchunk_predictions = list()\n",
    "\t\tfor j in range(test.shape[1]):\n",
    "\t\t\t# get the input pattern for this chunk and target\n",
    "\t\t\tpattern = test[i,j]\n",
    "\t\t\t# assume a nan forecast\n",
    "\t\t\tforecasts = array([nan for _ in range(len(lead_times))])\n",
    "\t\t\t# check we can make a forecast\n",
    "\t\t\tif has_data(pattern):\n",
    "\t\t\t\tpattern = pattern.reshape((1, len(pattern)))\n",
    "\t\t\t\t# forecast each lead time\n",
    "\t\t\t\tforecasts = list()\n",
    "\t\t\t\tfor k in range(len(lead_times)):\n",
    "\t\t\t\t\tyhat = models[j][k][0].predict(pattern)\n",
    "\t\t\t\t\tforecasts.append(yhat[0])\n",
    "\t\t\t\tforecasts = array(forecasts)\n",
    "\t\t\t# save forecasts for each lead time for this variable\n",
    "\t\t\tchunk_predictions.append(forecasts)\n",
    "\t\t# save forecasts for this chunk\n",
    "\t\tchunk_predictions = array(chunk_predictions)\n",
    "\t\tpredictions.append(chunk_predictions)\n",
    "\treturn array(predictions)\n",
    "\n",
    "# convert the test dataset in chunks to [chunk][variable][time] format\n",
    "def prepare_test_forecasts(test_chunks):\n",
    "\tpredictions = list()\n",
    "\t# enumerate chunks to forecast\n",
    "\tfor rows in test_chunks:\n",
    "\t\t# enumerate targets for chunk\n",
    "\t\tchunk_predictions = list()\n",
    "\t\tfor j in range(3, rows.shape[1]):\n",
    "\t\t\tyhat = rows[:, j]\n",
    "\t\t\tchunk_predictions.append(yhat)\n",
    "\t\tchunk_predictions = array(chunk_predictions)\n",
    "\t\tpredictions.append(chunk_predictions)\n",
    "\treturn array(predictions)\n",
    "\n",
    "# calculate the error between an actual and predicted value\n",
    "def calculate_error(actual, predicted):\n",
    "\t# give the full actual value if predicted is nan\n",
    "\tif isnan(predicted):\n",
    "\t\treturn abs(actual)\n",
    "\t# calculate abs difference\n",
    "\treturn abs(actual - predicted)\n",
    "\n",
    "# evaluate a forecast in the format [chunk][variable][time]\n",
    "def evaluate_forecasts(predictions, testset):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttotal_mae, times_mae = 0.0, [0.0 for _ in range(len(lead_times))]\n",
    "\ttotal_c, times_c = 0, [0 for _ in range(len(lead_times))]\n",
    "\t# enumerate test chunks\n",
    "\tfor i in range(len(test_chunks)):\n",
    "\t\t# convert to forecasts\n",
    "\t\tactual = testset[i]\n",
    "\t\tpredicted = predictions[i]\n",
    "\t\t# enumerate target variables\n",
    "\t\tfor j in range(predicted.shape[0]):\n",
    "\t\t\t# enumerate lead times\n",
    "\t\t\tfor k in range(len(lead_times)):\n",
    "\t\t\t\t# skip if actual in nan\n",
    "\t\t\t\tif isnan(actual[j, k]):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# calculate error\n",
    "\t\t\t\terror = calculate_error(actual[j, k], predicted[j, k])\n",
    "\t\t\t\t# update statistics\n",
    "\t\t\t\ttotal_mae += error\n",
    "\t\t\t\ttimes_mae[k] += error\n",
    "\t\t\t\ttotal_c += 1\n",
    "\t\t\t\ttimes_c[k] += 1\n",
    "\t# normalize summed absolute errors\n",
    "\ttotal_mae /= total_c\n",
    "\ttimes_mae = [times_mae[i]/times_c[i] for i in range(len(times_mae))]\n",
    "\treturn total_mae, times_mae\n",
    "\n",
    "# summarize scores\n",
    "def summarize_error(name, total_mae):\n",
    "\tprint('%s: %.3f MAE' % (name, total_mae))\n",
    "\n",
    "# prepare a list of ml models\n",
    "def get_models(models=dict()):\n",
    "\t# linear models\n",
    "\tmodels['lr'] = LinearRegression()\n",
    "\tmodels['lasso'] = Lasso()\n",
    "\tmodels['ridge'] = Ridge()\n",
    "\tmodels['en'] = ElasticNet()\n",
    "\tmodels['huber'] = HuberRegressor()\n",
    "\tmodels['llars'] = LassoLars()\n",
    "\tmodels['pa'] = PassiveAggressiveRegressor(max_iter=1000, tol=1e-3)\n",
    "\tmodels['sgd'] = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a suite of models\n",
    "def evaluate_models(models, train, test, actual):\n",
    "\tfor name, model in models.items():\n",
    "\t\t# fit models\n",
    "\t\tfits = fit_models(model, train)\n",
    "\t\t# make predictions\n",
    "\t\tpredictions = make_predictions(fits, test)\n",
    "\t\t# evaluate forecast\n",
    "\t\ttotal_mae, _ = evaluate_forecasts(predictions, actual)\n",
    "\t\t# summarize forecast\n",
    "\t\tsummarize_error(name, total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 10) (207, 39)\n",
      "Defined 8 models\n",
      "lr: 0.454 MAE\n",
      "lasso: 0.624 MAE\n",
      "ridge: 0.454 MAE\n",
      "en: 0.595 MAE\n",
      "huber: 0.434 MAE\n",
      "llars: 0.631 MAE\n",
      "pa: 0.843 MAE\n",
      "sgd: 0.457 MAE\n"
     ]
    }
   ],
   "source": [
    "# load supervised datasets\n",
    "train = load('AirQualityPrediction/supervised_train.npy', allow_pickle=True)\n",
    "test = load('AirQualityPrediction/supervised_test.npy', allow_pickle=True)\n",
    "print(train.shape, test.shape)\n",
    "# load test chunks for validation\n",
    "testset = loadtxt('AirQualityPrediction/naive_test.csv', delimiter=',')\n",
    "test_chunks = to_chunks(testset)\n",
    "actual = prepare_test_forecasts(test_chunks)\n",
    "# prepare list of models\n",
    "models = get_models()\n",
    "# evaluate models\n",
    "evaluate_models(models, train, test, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same framework to evaluate the performance of a suite of nonlinear and ensemble machine learning algorithms.\n",
    "\n",
    "**Specifically:**\n",
    "\n",
    "#### Nonlinear Algorithms\n",
    "\n",
    "1. k-Nearest Neighbors\n",
    "2. Classification and Regression Trees\n",
    "3. Extra Tree\n",
    "4. Support Vector Regression\n",
    "\n",
    "#### Ensemble Algorithms\n",
    "\n",
    "1. Adaboost\n",
    "2. Bagged Decision Trees\n",
    "3. Random Forest\n",
    "4. Extra Trees\n",
    "5. Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check nonlinear algorithms\n",
    "from numpy import load\n",
    "from numpy import loadtxt\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from numpy import count_nonzero\n",
    "from numpy import unique\n",
    "from numpy import array\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# split the dataset by 'chunkID', return a list of chunks\n",
    "def to_chunks(values, chunk_ix=0):\n",
    "\tchunks = list()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values[:, chunk_ix] == chunk_id\n",
    "\t\tchunks.append(values[selection, :])\n",
    "\treturn chunks\n",
    "\n",
    "# return true if the array has any non-nan values\n",
    "def has_data(data):\n",
    "\treturn count_nonzero(isnan(data)) < len(data)\n",
    "\n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2, 3, 4, 5, 10, 17, 24, 48, 72]\n",
    "\n",
    "# fit a single model\n",
    "def fit_model(model, X, y):\n",
    "\t# clone the model configuration\n",
    "\tlocal_model = clone(model)\n",
    "\t# fit the model\n",
    "\tlocal_model.fit(X, y)\n",
    "\treturn local_model\n",
    "\n",
    "# fit one model for each variable and each forecast lead time [var][time][model]\n",
    "def fit_models(model, train):\n",
    "\t# prepare structure for saving models\n",
    "\tmodels = [[list() for _ in range(train.shape[1])] for _ in range(train.shape[0])]\n",
    "\t# enumerate vars\n",
    "\tfor i in range(train.shape[0]):\n",
    "\t\t# enumerate lead times\n",
    "\t\tfor j in range(train.shape[1]):\n",
    "\t\t\t# get data\n",
    "\t\t\tdata = train[i, j]\n",
    "\t\t\tX, y = data[:, :-1], data[:, -1]\n",
    "\t\t\t# fit model\n",
    "\t\t\tlocal_model = fit_model(model, X, y)\n",
    "\t\t\tmodels[i][j].append(local_model)\n",
    "\treturn models\n",
    "\n",
    "# return forecasts as [chunks][var][time]\n",
    "def make_predictions(models, test):\n",
    "\tlead_times = get_lead_times()\n",
    "\tpredictions = list()\n",
    "\t# enumerate chunks\n",
    "\tfor i in range(test.shape[0]):\n",
    "\t\t# enumerate variables\n",
    "\t\tchunk_predictions = list()\n",
    "\t\tfor j in range(test.shape[1]):\n",
    "\t\t\t# get the input pattern for this chunk and target\n",
    "\t\t\tpattern = test[i,j]\n",
    "\t\t\t# assume a nan forecast\n",
    "\t\t\tforecasts = array([nan for _ in range(len(lead_times))])\n",
    "\t\t\t# check we can make a forecast\n",
    "\t\t\tif has_data(pattern):\n",
    "\t\t\t\tpattern = pattern.reshape((1, len(pattern)))\n",
    "\t\t\t\t# forecast each lead time\n",
    "\t\t\t\tforecasts = list()\n",
    "\t\t\t\tfor k in range(len(lead_times)):\n",
    "\t\t\t\t\tyhat = models[j][k][0].predict(pattern)\n",
    "\t\t\t\t\tforecasts.append(yhat[0])\n",
    "\t\t\t\tforecasts = array(forecasts)\n",
    "\t\t\t# save forecasts for each lead time for this variable\n",
    "\t\t\tchunk_predictions.append(forecasts)\n",
    "\t\t# save forecasts for this chunk\n",
    "\t\tchunk_predictions = array(chunk_predictions)\n",
    "\t\tpredictions.append(chunk_predictions)\n",
    "\treturn array(predictions)\n",
    "\n",
    "# convert the test dataset in chunks to [chunk][variable][time] format\n",
    "def prepare_test_forecasts(test_chunks):\n",
    "\tpredictions = list()\n",
    "\t# enumerate chunks to forecast\n",
    "\tfor rows in test_chunks:\n",
    "\t\t# enumerate targets for chunk\n",
    "\t\tchunk_predictions = list()\n",
    "\t\tfor j in range(3, rows.shape[1]):\n",
    "\t\t\tyhat = rows[:, j]\n",
    "\t\t\tchunk_predictions.append(yhat)\n",
    "\t\tchunk_predictions = array(chunk_predictions)\n",
    "\t\tpredictions.append(chunk_predictions)\n",
    "\treturn array(predictions)\n",
    "\n",
    "# calculate the error between an actual and predicted value\n",
    "def calculate_error(actual, predicted):\n",
    "\t# give the full actual value if predicted is nan\n",
    "\tif isnan(predicted):\n",
    "\t\treturn abs(actual)\n",
    "\t# calculate abs difference\n",
    "\treturn abs(actual - predicted)\n",
    "\n",
    "# evaluate a forecast in the format [chunk][variable][time]\n",
    "def evaluate_forecasts(predictions, testset):\n",
    "\tlead_times = get_lead_times()\n",
    "\ttotal_mae, times_mae = 0.0, [0.0 for _ in range(len(lead_times))]\n",
    "\ttotal_c, times_c = 0, [0 for _ in range(len(lead_times))]\n",
    "\t# enumerate test chunks\n",
    "\tfor i in range(len(test_chunks)):\n",
    "\t\t# convert to forecasts\n",
    "\t\tactual = testset[i]\n",
    "\t\tpredicted = predictions[i]\n",
    "\t\t# enumerate target variables\n",
    "\t\tfor j in range(predicted.shape[0]):\n",
    "\t\t\t# enumerate lead times\n",
    "\t\t\tfor k in range(len(lead_times)):\n",
    "\t\t\t\t# skip if actual in nan\n",
    "\t\t\t\tif isnan(actual[j, k]):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# calculate error\n",
    "\t\t\t\terror = calculate_error(actual[j, k], predicted[j, k])\n",
    "\t\t\t\t# update statistics\n",
    "\t\t\t\ttotal_mae += error\n",
    "\t\t\t\ttimes_mae[k] += error\n",
    "\t\t\t\ttotal_c += 1\n",
    "\t\t\t\ttimes_c[k] += 1\n",
    "\t# normalize summed absolute errors\n",
    "\ttotal_mae /= total_c\n",
    "\ttimes_mae = [times_mae[i]/times_c[i] for i in range(len(times_mae))]\n",
    "\treturn total_mae, times_mae\n",
    "\n",
    "# summarize scores\n",
    "def summarize_error(name, total_mae):\n",
    "\tprint('%s: %.3f MAE' % (name, total_mae))\n",
    "\n",
    "# prepare a list of ml models\n",
    "def get_models(models=dict()):\n",
    "\t# non-linear models\n",
    "\tmodels['knn'] = KNeighborsRegressor(n_neighbors=7)\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['extra'] = ExtraTreeRegressor()\n",
    "\tmodels['svmr'] = SVR()\n",
    "\t# # ensemble models\n",
    "\tn_trees = 100\n",
    "\tmodels['ada'] = AdaBoostRegressor(n_estimators=n_trees)\n",
    "\tmodels['bag'] = BaggingRegressor(n_estimators=n_trees)\n",
    "\tmodels['rf'] = RandomForestRegressor(n_estimators=n_trees)\n",
    "\tmodels['et'] = ExtraTreesRegressor(n_estimators=n_trees)\n",
    "\tmodels['gbm'] = GradientBoostingRegressor(n_estimators=n_trees)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a suite of models\n",
    "def evaluate_models(models, train, test, actual):\n",
    "\tfor name, model in models.items():\n",
    "\t\t# fit models\n",
    "\t\tfits = fit_models(model, train)\n",
    "\t\t# make predictions\n",
    "\t\tpredictions = make_predictions(fits, test)\n",
    "\t\t# evaluate forecast\n",
    "\t\ttotal_mae, _ = evaluate_forecasts(predictions, actual)\n",
    "\t\t# summarize forecast\n",
    "\t\tsummarize_error(name, total_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 10) (207, 39)\n",
      "Defined 9 models\n",
      "knn: 0.484 MAE\n",
      "cart: 0.632 MAE\n",
      "extra: 0.631 MAE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/tendulkar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-6b7b6b16c846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-b976e5584a40>\u001b[0m in \u001b[0;36mevaluate_models\u001b[0;34m(models, train, test, actual)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# fit models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mfits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-b976e5584a40>\u001b[0m in \u001b[0;36mfit_models\u001b[0;34m(model, train)\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                         \u001b[0mlocal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-b976e5584a40>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlocal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mlocal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load supervised datasets\n",
    "train = load('AirQualityPrediction/supervised_train.npy', allow_pickle=True)\n",
    "test = load('AirQualityPrediction/supervised_test.npy', allow_pickle=True)\n",
    "print(train.shape, test.shape)\n",
    "# load test chunks for validation\n",
    "testset = loadtxt('AirQualityPrediction/naive_test.csv', delimiter=',')\n",
    "test_chunks = to_chunks(testset)\n",
    "actual = prepare_test_forecasts(test_chunks)\n",
    "# prepare list of models\n",
    "models = get_models()\n",
    "# evaluate models\n",
    "evaluate_models(models, train, test, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
